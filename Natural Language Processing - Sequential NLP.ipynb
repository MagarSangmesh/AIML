{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25d34f0",
   "metadata": {},
   "source": [
    "# Part A - 30 Marks\n",
    "## DOMAIN: Digital content and entertainment industry\n",
    "\n",
    "## CONTEXT: \n",
    "####                        The objective of this project is to build a text classification model that analyses the customer's sentiments based on their reviews in the IMDB database. The model uses a complex deep learning model to build an embedding layer followed by a classification algorithm to analyse the sentiment of the customers.\n",
    "\n",
    "## DATA DESCRIPTION: \n",
    "####                                              The Dataset of 50,000 movie reviews from IMDB, labelled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word. Use the first 20 words from each review to speed up training, using a max vocabulary size of 10,000. As a convention, 0 does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "\n",
    "## PROJECT OBJECTIVE: \n",
    "### To Build a sequential NLP classifier which can use input text parameters to determine the customer sentiments.\n",
    "\n",
    "#### 1. Import and analyse the data set. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31da8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, TextVectorization, LSTM, Bidirectional, Embedding\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a39151",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words = 10_000,\n",
    "                                                                     #maxlen = 20\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196b888",
   "metadata": {},
   "source": [
    "#### 2. Perform relevant sequence adding on the data. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9ffefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded = []\n",
    "x_test_padded = []\n",
    "\n",
    "for train_sample, test_sample in zip(x_train, x_test):\n",
    "    if len(train_sample) < 20:\n",
    "        x_train_padded.append(\n",
    "            train_sample + ( [\"0\"] * (20 - len(train_sample) ) )\n",
    "        )\n",
    "    else:\n",
    "        x_train_padded.append(\n",
    "            train_sample[ : 20 ]\n",
    "        )\n",
    "    if len(test_sample) < 20:\n",
    "        x_test_padded.append(\n",
    "            test_sample + ( [\"0\"] * (20 - len(test_sample) ) )\n",
    "        )\n",
    "    else:\n",
    "        x_test_padded.append(\n",
    "            test_sample[ : 20 ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e1ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded = np.asarray(x_train_padded, dtype = np.int32)\n",
    "x_test_padded = np.asarray(x_test_padded, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac236d",
   "metadata": {},
   "source": [
    "#### 3. Perform following data analysis: [5 Marks]\n",
    "\n",
    "#### •Print shape of features and labels\n",
    "\n",
    "#### •Print value of any one feature and it's label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "708714d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 20), (25000, 20), (25000,), (25000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_padded.shape, x_test_padded.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bb4a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25] \n",
      "\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"{x_train_padded[0]} \\n\\n {y_train[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec5b28",
   "metadata": {},
   "source": [
    "4. Decode the feature value to get original sentence [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc9bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = keras.datasets.imdb.get_word_index()\n",
    "vocab[\"0\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6eefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = { index : word for word, index in vocab.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5657dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "\n",
    "for sample in x_train_padded[ : 20 ] :\n",
    "    reviews.append(\" \".join([index_to_word.get(index - 3, \"0\") for index in sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d5a85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you                           1 \n",
      "0 big hair big boobs bad music and a giant safety pin these are the words to best describe this                                                         0 \n",
      "0 this has to be one of the worst films of the 1990s when my friends i were watching this                                                               0 \n",
      "0 the 0 0 at storytelling the traditional sort many years after the event i can still see in my                                                         1 \n",
      "0 worst mistake of my life br br i picked this movie up at target for 5 because i figured                                                               0 \n",
      "0 begins better than it ends funny that the russian submarine crew 0 all other actors it's like those scenes                                            0 \n",
      "0 lavish production values and solid performances in this straightforward adaption of jane 0 satirical classic about the marriage game                  1 \n",
      "0 the 0 tells the story of the four hamilton siblings teenager francis 0 0 twins 0 joseph 0 0                                                           0 \n",
      "0 just got out and cannot believe what a brilliant documentary this is rarely do you walk out of a                                                      1 \n",
      "0 this movie has many problem associated with it that makes it come off like a low budget class project                                                 0 \n",
      "0 french horror cinema has seen something of a revival over the last couple of years with great films such                                              1 \n",
      "0 when i rented this movie i had very low expectations but when i saw it i realized that the                                                            0 \n",
      "0 i love cheesy horror flicks i don't care if the acting is sub par or whether the monsters look                                                        0 \n",
      "0 anyone who could find redeeming value in this piece of crap ought to have their head examined we have                                                 0 \n",
      "0 b movie at best sound effects are pretty good lame concept decent execution i suppose it's a rental br                                                0 \n",
      "0 a total waste of time just throw in a few explosions non stop fighting exotic cars a deranged millionaire                                             0 \n",
      "0 laputa castle in the sky is the bomb the message is as strong as his newer works and more                                                             1 \n",
      "0 at the height of the 0 big 0 racism row in 2007 involving 0 0 and the late 0                                                                          1 \n",
      "0 i have only had the luxury of seeing this movie once when i was rather young so much of                                                               0 \n",
      "0 chances are is a charming romantic fantasy about a woman 0 shepherd whose husband christopher 0 is killed shortly                                     1 \n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(reviews, y_train[ : 20 ] ) :\n",
    "    print(f\"{review :150}  {sentiment} \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f9ed9",
   "metadata": {},
   "source": [
    "#### 5. Design, train, tune and test a sequential model. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55781614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(data, vocab_size = 10_000):\n",
    "    vectorized_data = np.zeros(shape = (len(data), vocab_size,))\n",
    "    for index, sample in enumerate(data):\n",
    "        for word_index in sample:\n",
    "            #print(index, word_index)\n",
    "            if word_index != \"?\":\n",
    "                vectorized_data[int(index), int(word_index)] = 1\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f811d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded = vectorize_data(x_train_padded)\n",
    "x_test_padded = vectorize_data(x_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf437c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 10000), (25000, 10000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_padded.shape, x_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7295bf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                160016    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,801\n",
      "Trainable params: 160,753\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape = 10_000))\n",
    "model.add(Dense(16, activation = \"relu\"))\n",
    "model.add(Dense(16, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation = \"relu\"))\n",
    "model.add(Dense(8, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1484c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.RMSprop(),\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c62651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "176/176 [==============================] - 4s 17ms/step - loss: 0.6903 - accuracy: 0.5765 - val_loss: 0.6815 - val_accuracy: 0.4924 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.7343 - val_loss: 0.6373 - val_accuracy: 0.6228 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.4366 - accuracy: 0.7985 - val_loss: 0.5719 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.3589 - accuracy: 0.8467 - val_loss: 0.6007 - val_accuracy: 0.7064 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.2917 - accuracy: 0.8800 - val_loss: 0.6615 - val_accuracy: 0.6928 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.2380 - accuracy: 0.9062 - val_loss: 0.7577 - val_accuracy: 0.6876 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1616 - accuracy: 0.9440 - val_loss: 0.7516 - val_accuracy: 0.6896 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1434 - accuracy: 0.9506 - val_loss: 0.7619 - val_accuracy: 0.6868 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1305 - accuracy: 0.9558 - val_loss: 0.7855 - val_accuracy: 0.6864 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.9614 - val_loss: 0.7908 - val_accuracy: 0.6864 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.1195 - accuracy: 0.9608 - val_loss: 0.7940 - val_accuracy: 0.6868 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9629 - val_loss: 0.7971 - val_accuracy: 0.6860 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9614 - val_loss: 0.7977 - val_accuracy: 0.6864 - lr: 1.0000e-06\n",
      "Epoch 14/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1158 - accuracy: 0.9619 - val_loss: 0.7974 - val_accuracy: 0.6864 - lr: 1.0000e-06\n",
      "Epoch 15/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1174 - accuracy: 0.9622 - val_loss: 0.7988 - val_accuracy: 0.6868 - lr: 1.0000e-06\n",
      "Epoch 16/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1164 - accuracy: 0.9624 - val_loss: 0.7983 - val_accuracy: 0.6864 - lr: 1.0000e-07\n",
      "Epoch 17/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1161 - accuracy: 0.9629 - val_loss: 0.7987 - val_accuracy: 0.6860 - lr: 1.0000e-07\n",
      "Epoch 18/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.9621 - val_loss: 0.7981 - val_accuracy: 0.6864 - lr: 1.0000e-07\n",
      "Epoch 19/20\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.1163 - accuracy: 0.9627 - val_loss: 0.7984 - val_accuracy: 0.6864 - lr: 1.0000e-08\n",
      "Epoch 20/20\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.1173 - accuracy: 0.9623 - val_loss: 0.7987 - val_accuracy: 0.6864 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train_padded,\n",
    "    y = y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 20,\n",
    "    validation_split = 0.1,\n",
    "    callbacks = [ keras.callbacks.ReduceLROnPlateau(patience = 3), keras.callbacks.ModelCheckpoint(filepath = \"./best.keras\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be326f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step - loss: 0.8789 - accuracy: 0.6635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8789253830909729, 0.6634799838066101]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_padded, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76caa37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d20cd",
   "metadata": {},
   "source": [
    "i think i gona explore more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "644de73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 256)               2560256   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,602,465\n",
      "Trainable params: 2,602,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape = 10_000))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(16, activation = \"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "749d978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.RMSprop(),\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca5a8b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "176/176 [==============================] - 7s 33ms/step - loss: 0.6192 - accuracy: 0.6531 - val_loss: 0.5556 - val_accuracy: 0.7052 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.4915 - accuracy: 0.7733 - val_loss: 0.5430 - val_accuracy: 0.7196 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.3863 - accuracy: 0.8429 - val_loss: 0.5903 - val_accuracy: 0.7224 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.2502 - accuracy: 0.9120 - val_loss: 0.7470 - val_accuracy: 0.7012 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.1331 - accuracy: 0.9593 - val_loss: 1.0166 - val_accuracy: 0.7028 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "176/176 [==============================] - 6s 33ms/step - loss: 0.0463 - accuracy: 0.9911 - val_loss: 1.4147 - val_accuracy: 0.7072 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.0314 - accuracy: 0.9931 - val_loss: 1.6526 - val_accuracy: 0.7052 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "176/176 [==============================] - 6s 31ms/step - loss: 0.0239 - accuracy: 0.9952 - val_loss: 1.8434 - val_accuracy: 0.7008 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 1.8715 - val_accuracy: 0.7028 - lr: 1.0000e-05\n",
      "Epoch 10/20\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 1.8980 - val_accuracy: 0.7040 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 1.9274 - val_accuracy: 0.7020 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.0170 - accuracy: 0.9966 - val_loss: 1.9301 - val_accuracy: 0.7020 - lr: 1.0000e-06\n",
      "Epoch 13/20\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 1.9330 - val_accuracy: 0.7016 - lr: 1.0000e-06\n",
      "Epoch 14/20\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 1.9354 - val_accuracy: 0.7012 - lr: 1.0000e-06\n",
      "Epoch 15/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.0170 - accuracy: 0.9968 - val_loss: 1.9357 - val_accuracy: 0.7012 - lr: 1.0000e-07\n",
      "Epoch 16/20\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 1.9360 - val_accuracy: 0.7012 - lr: 1.0000e-07\n",
      "Epoch 17/20\n",
      "176/176 [==============================] - 6s 33ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 1.9362 - val_accuracy: 0.7012 - lr: 1.0000e-07\n",
      "Epoch 18/20\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.0168 - accuracy: 0.9966 - val_loss: 1.9362 - val_accuracy: 0.7012 - lr: 1.0000e-08\n",
      "Epoch 19/20\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 1.9362 - val_accuracy: 0.7012 - lr: 1.0000e-08\n",
      "Epoch 20/20\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 1.9363 - val_accuracy: 0.7012 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train_padded,\n",
    "    y = y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 20,\n",
    "    validation_split = 0.1,\n",
    "    callbacks = [ keras.callbacks.ReduceLROnPlateau(patience = 3), keras.callbacks.ModelCheckpoint(filepath = \"./best.keras\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c61e476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 2.0511 - accuracy: 0.6858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0511038303375244, 0.6857600212097168]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_padded, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca8194",
   "metadata": {},
   "source": [
    "I think i have to increase sequence length bcz things would've been better had we used the entire reviews rather than only the first 20 words of them\n",
    "\n",
    "#### 6. Use the designed model to print the prediction on any one sample. [5 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab95abdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 261ms/step\n",
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an \n",
      "predicted : 1.0 \t real : 1\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_train_padded[np.newaxis, 6])\n",
    "print(\" \".join(index_to_word[index] for index in x_train[0]), f\"\\npredicted : {pred.item()} \\t real : {y_test[6]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ee0e0",
   "metadata": {},
   "source": [
    "# Part B - 30 Marks\n",
    "\n",
    "## DOMAIN: Social media analytics\n",
    "\n",
    "## CONTEXT: \n",
    "####                       Past studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag based supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to other tweets and detecting sarcasm in these requires the availability of contextual tweets.In this hands-on project, the goal is to build a model to detect whether a sentence is sarcastic or not, using Bidirectional LSTMs.\n",
    "\n",
    "## DATA DESCRIPTION:\n",
    "\n",
    "#### The dataset is collected from two news websites, theonion.com and huffingtonpost.com.\n",
    "\n",
    "#### This new dataset has the following advantages over the existing Twitter datasets:\n",
    "\n",
    "#### Since news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This reduces the sparsity and also increases the chance of inding pre-trained embeddings.\n",
    "\n",
    "#### Furthermore, since the sole purpose of TheOnion is to publish sarcastic news, we get high-quality labels with much less noise as compared to Twitter datasets.\n",
    "\n",
    "#### Unlike tweets that reply to other tweets, the news headlines obtained are self-contained. This would help us in teasing apart the real sarcastic elements\n",
    "\n",
    "####  Content: Each record consists of three attributes:\n",
    "\n",
    "#### is_sarcastic: 1 if the record is sarcastic otherwise 0\n",
    "#### headline: the headline of the news article\n",
    "#### article_link: link to the original news article. Useful in collecting supplementary data\n",
    "#### Reference: https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection\n",
    "\n",
    "## PROJECT OBJECTIVE: \n",
    "### Build a sequential NLP classifier which can use input text parameters to determine the customer sentiments.\n",
    "\n",
    "#### 1. Read and explore the data [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78de5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4474bb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>1</td>\n",
       "      <td>jews to celebrate rosh hashasha or something</td>\n",
       "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>1</td>\n",
       "      <td>internal affairs investigator disappointed con...</td>\n",
       "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>0</td>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>1</td>\n",
       "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
       "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>1</td>\n",
       "      <td>dad clarifies this not a food stop</td>\n",
       "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28619 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic                                           headline  \\\n",
       "0                 1  thirtysomething scientists unveil doomsday clo...   \n",
       "1                 0  dem rep. totally nails why congress is falling...   \n",
       "2                 0  eat your veggies: 9 deliciously different recipes   \n",
       "3                 1  inclement weather prevents liar from getting t...   \n",
       "4                 1  mother comes pretty close to using word 'strea...   \n",
       "...             ...                                                ...   \n",
       "28614             1       jews to celebrate rosh hashasha or something   \n",
       "28615             1  internal affairs investigator disappointed con...   \n",
       "28616             0  the most beautiful acceptance speech this week...   \n",
       "28617             1  mars probe destroyed by orbiting spielberg-gat...   \n",
       "28618             1                 dad clarifies this not a food stop   \n",
       "\n",
       "                                            article_link  \n",
       "0      https://www.theonion.com/thirtysomething-scien...  \n",
       "1      https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2      https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3      https://local.theonion.com/inclement-weather-p...  \n",
       "4      https://www.theonion.com/mother-comes-pretty-c...  \n",
       "...                                                  ...  \n",
       "28614  https://www.theonion.com/jews-to-celebrate-ros...  \n",
       "28615  https://local.theonion.com/internal-affairs-in...  \n",
       "28616  https://www.huffingtonpost.com/entry/andrew-ah...  \n",
       "28617  https://www.theonion.com/mars-probe-destroyed-...  \n",
       "28618  https://www.theonion.com/dad-clarifies-this-no...  \n",
       "\n",
       "[28619 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faeff85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28619.000000</td>\n",
       "      <td>28619</td>\n",
       "      <td>28619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28503</td>\n",
       "      <td>28617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>'no way to prevent this,' says only nation whe...</td>\n",
       "      <td>https://politics.theonion.com/nation-not-sure-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.476397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_sarcastic                                           headline  \\\n",
       "count   28619.000000                                              28619   \n",
       "unique           NaN                                              28503   \n",
       "top              NaN  'no way to prevent this,' says only nation whe...   \n",
       "freq             NaN                                                 12   \n",
       "mean        0.476397                                                NaN   \n",
       "std         0.499451                                                NaN   \n",
       "min         0.000000                                                NaN   \n",
       "25%         0.000000                                                NaN   \n",
       "50%         0.000000                                                NaN   \n",
       "75%         1.000000                                                NaN   \n",
       "max         1.000000                                                NaN   \n",
       "\n",
       "                                             article_link  \n",
       "count                                               28619  \n",
       "unique                                              28617  \n",
       "top     https://politics.theonion.com/nation-not-sure-...  \n",
       "freq                                                    2  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include= \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bd5f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28619 entries, 0 to 28618\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   is_sarcastic  28619 non-null  int64 \n",
      " 1   headline      28619 non-null  object\n",
      " 2   article_link  28619 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 670.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9c0f16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    13634\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"is_sarcastic\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e8d57",
   "metadata": {},
   "source": [
    "No class is under-represented in this datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "097d30e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x = [np.log(len(text)) for text in dataset[\"headline\"]], hue = dataset[\"is_sarcastic\"], bins = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef81c6b",
   "metadata": {},
   "source": [
    "2. Retain relevant columns [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "975d2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(\"article_link\", axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c602712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_sarcastic', 'headline'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675fd16c",
   "metadata": {},
   "source": [
    "#### 3. Get length of each sentence [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05f5da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for text in dataset[\"headline\"]:\n",
    "    lengths.append(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539471c3",
   "metadata": {},
   "source": [
    "#### 4. Define parameters [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01333a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of words I'll be taking                     :50\n",
      "Maximum possible length of each sentence           :926\n",
      "Embedding Vector I'll be using                     :GloVe's Twitter 27 Billion tokens and 25 dimensional words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{\"Number of words I'll be taking \" :50} :50\n",
    "{\"Maximum possible length of each sentence\" :50} :{max(lengths)}\n",
    "{\"Embedding Vector I'll be using\" :50} :GloVe's Twitter 27 Billion tokens and 25 dimensional words\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93333dc9",
   "metadata": {},
   "source": [
    "#### 5. Get indices for words [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ebe4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicer = TextVectorization(\n",
    "    output_mode = \"int\",\n",
    "    #max_tokens = 2000,\n",
    "    output_sequence_length = 50\n",
    ")\n",
    "\n",
    "indicer.adapt(dataset[\"headline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d8957",
   "metadata": {},
   "source": [
    "#### 6. Create features and labels [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75072137",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = np.ndarray(shape = (28_619, 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25dc9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, headline in enumerate(dataset[\"headline\"]): #limiting the dataset due to time constraints\n",
    "    #print(headline)\n",
    "    tensor = (indicer(headline))\n",
    "    if tensor.shape == (0,):\n",
    "        tensor = np.zeros((50,))\n",
    "    vectorized_data[index] = tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d531e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data.npz\", vectorized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15762400",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(dataset[\"is_sarcastic\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26f577cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e671188",
   "metadata": {},
   "source": [
    "#### 7. Get vocabulary size [3 marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "722695a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29674"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicer.vocabulary_size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615726d1",
   "metadata": {},
   "source": [
    "#### 8. Create a weight matrix using GloVe embeddings [3 marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d60fa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"glove.twitter.27B.25d.txt\" and \"glove.twitter.27B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float16\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5178a",
   "metadata": {},
   "source": [
    "Assigning indices according to our vocabulary, not the GloVe vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_embeddings = np.zeros((29683, 25))\n",
    "for index, word in enumerate(indicer.get_vocabulary()):\n",
    "    #print(word)\n",
    "    indice_embeddings[index] = embeddings_dict.get(word, np.zeros((25)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9bdee4",
   "metadata": {},
   "source": [
    "#### 9. Define and compile a Bidirectional LSTM model. [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cddc32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 25)            742075    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 50, 16)           2176      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50, 16)            0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 32)               4224      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 748,508\n",
      "Trainable params: 6,433\n",
      "Non-trainable params: 742,075\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape = (50))\n",
    "\n",
    "embeddings = Embedding(29683,\n",
    "                       25,\n",
    "                       embeddings_initializer = keras.initializers.Constant(indice_embeddings),\n",
    "                       trainable = False\n",
    "                       )(inputs)\n",
    "features = Bidirectional(LSTM(8, unroll = True, return_sequences = True), )(embeddings)\n",
    "features = Dropout(0.3)(features)\n",
    "features = Bidirectional(LSTM(16, unroll = True),)(features)\n",
    "features = Dropout(0.3)(features)\n",
    "outputs = Dense(1, activation = \"sigmoid\")(features)\n",
    "\n",
    "MODEL = keras.Model(inputs, outputs)\n",
    "MODEL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d169f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.compile(\n",
    "    optimizer = \"rmsprop\",\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff386e7",
   "metadata": {},
   "source": [
    "#### 10. Fit the model and check the validation accuracy [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc271c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 30s 144ms/step - loss: 0.6923 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n"
     ]
    }
   ],
   "source": [
    "history = MODEL.fit(vectorized_data[ : 25_000], \n",
    "                    targets[ : 25_000],\n",
    "                    epochs = 100,\n",
    "                    batch_size = 512,\n",
    "                    validation_split = 0.1,\n",
    "                    callbacks = [ keras.callbacks.ModelCheckpoint(filepath=\"./best_part2.keras\"),\n",
    "                                 keras.callbacks.ReduceLROnPlateau(patience = 10)\n",
    "                                ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "daa54447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 10ms/step - loss: 0.6920 - accuracy: 0.5239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6920068264007568, 0.523901641368866]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.evaluate(vectorized_data[ 25_000 : ], targets[ 25_000 : ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62372d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2096"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del MODEL\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41fa2c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 50, 25)            742075    \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 16)               2176      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 744,268\n",
      "Trainable params: 2,193\n",
      "Non-trainable params: 742,075\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape = (50))\n",
    "\n",
    "embeddings = Embedding(29683,\n",
    "                       25,\n",
    "                       embeddings_initializer = keras.initializers.Constant(indice_embeddings),\n",
    "                       trainable = False\n",
    "                       )(inputs)\n",
    "features = Bidirectional(LSTM(64, unroll = True, return_sequences = True), )(embeddings)\n",
    "features = Dropout(0.3)(features)\n",
    "features = Bidirectional(LSTM(32, unroll = True, return_sequences = True),)(features)\n",
    "features = Dropout(0.3)(features)\n",
    "features = Bidirectional(LSTM(16, unroll = True, return_sequences = True), )(embeddings)\n",
    "features = Dropout(0.3)(features)\n",
    "features = Bidirectional(LSTM(8, unroll = True, ), )(embeddings)\n",
    "features = Dropout(0.3)(features)\n",
    "outputs = Dense(1, activation = \"sigmoid\")(features)\n",
    "\n",
    "MODEL2 = keras.Model(inputs, outputs)\n",
    "MODEL2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7dcab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL2.compile(\n",
    "    optimizer = \"rmsprop\",\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c7824f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 15s 69ms/step - loss: 0.6923 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 34ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-07\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-08\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-09\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-10\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 2s 37ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-11\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6922 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.6920 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 2s 35ms/step - loss: 0.6921 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5260 - lr: 1.0000e-12\n"
     ]
    }
   ],
   "source": [
    "history = MODEL2.fit(vectorized_data[ : 25_000], \n",
    "                    targets[ : 25_000],\n",
    "                    epochs = 100,\n",
    "                    batch_size = 512,\n",
    "                    validation_split = 0.1,\n",
    "                    callbacks = [ keras.callbacks.ModelCheckpoint(filepath=\"./best_part2.keras\"),\n",
    "                                 keras.callbacks.ReduceLROnPlateau(patience = 10)\n",
    "                                ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06edf063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 5ms/step - loss: 0.6920 - accuracy: 0.5239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.69200599193573, 0.523901641368866]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL2.evaluate(vectorized_data[ 25_000 : ], targets[ 25_000 : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce92c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application is used to convert notebook files (*.ipynb)\n",
      "        to various other formats.\n",
      "\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "=======\n",
      "The options below are convenience aliases to configurable class-options,\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\n",
      "To see all configurable class-options for some <cmd>, use:\n",
      "    <cmd> --help-all\n",
      "\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "    Equivalent to: [--Application.log_level=10]\n",
      "--show-config\n",
      "    Show the application's configuration (human-readable format)\n",
      "    Equivalent to: [--Application.show_config=True]\n",
      "--show-config-json\n",
      "    Show the application's configuration (json format)\n",
      "    Equivalent to: [--Application.show_config_json=True]\n",
      "--generate-config\n",
      "    generate default config file\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\n",
      "-y\n",
      "    Answer yes to any questions instead of prompting.\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
      "--allow-errors\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
      "--stdin\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only\n",
      "            relevant when converting to notebook format)\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
      "--clear-output\n",
      "    Clear output of current file and save in place,\n",
      "            overwriting the existing notebook.\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
      "--no-prompt\n",
      "    Exclude input and output prompts from converted document.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
      "--no-input\n",
      "    Exclude input cells and output prompts from converted document.\n",
      "            This mode is ideal for generating code-free reports.\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
      "--allow-chromium-download\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
      "--disable-chromium-sandbox\n",
      "    Disable chromium security sandbox when converting to PDF..\n",
      "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
      "--show-input\n",
      "    Shows code input. This flag is only useful for dejavu users.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
      "--embed-images\n",
      "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
      "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
      "--log-level=<Enum>\n",
      "    Set the log level by value or name.\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
      "    Default: 30\n",
      "    Equivalent to: [--Application.log_level]\n",
      "--config=<Unicode>\n",
      "    Full path of a config file.\n",
      "    Default: ''\n",
      "    Equivalent to: [--JupyterApp.config_file]\n",
      "--to=<Unicode>\n",
      "    The export format to be used, either one of the built-in formats\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n",
      "            or a dotted object name that represents the import path for an\n",
      "            ``Exporter`` class\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.export_format]\n",
      "--template=<Unicode>\n",
      "    Name of the template to use\n",
      "    Default: ''\n",
      "    Equivalent to: [--TemplateExporter.template_name]\n",
      "--template-file=<Unicode>\n",
      "    Name of the template file to use\n",
      "    Default: None\n",
      "    Equivalent to: [--TemplateExporter.template_file]\n",
      "--theme=<Unicode>\n",
      "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
      "    as prebuilt extension for the lab template)\n",
      "    Default: 'light'\n",
      "    Equivalent to: [--HTMLExporter.theme]\n",
      "--writer=<DottedObjectName>\n",
      "    Writer class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: 'FilesWriter'\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\n",
      "--post=<DottedOrNone>\n",
      "    PostProcessor class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
      "--output=<Unicode>\n",
      "    overwrite base name use for output files.\n",
      "                can only be used when converting one notebook at a time.\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.output_base]\n",
      "--output-dir=<Unicode>\n",
      "    Directory to write output(s) to. Defaults\n",
      "                                  to output to the directory of each notebook. To recover\n",
      "                                  previous default behaviour (outputting to the current\n",
      "                                  working directory) use . as the flag value.\n",
      "    Default: ''\n",
      "    Equivalent to: [--FilesWriter.build_directory]\n",
      "--reveal-prefix=<Unicode>\n",
      "    The URL prefix for reveal.js (version 3.x).\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
      "            of reveal.js.\n",
      "            For speaker notes to work, this must be a relative path to a local\n",
      "            copy of reveal.js: e.g., \"reveal.js\".\n",
      "            If a relative path is given, it must be a subdirectory of the\n",
      "            current directory (from which the server is run).\n",
      "            See the usage documentation\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
      "            for more details.\n",
      "    Default: ''\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
      "--nbformat=<Enum>\n",
      "    The nbformat version to write.\n",
      "            Use this to downgrade notebooks.\n",
      "    Choices: any of [1, 2, 3, 4]\n",
      "    Default: 4\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\n",
      "\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\n",
      "\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
      "            'classic'. You can specify the flavor of the format used.\n",
      "\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
      "\n",
      "            You can also pipe the output to stdout, rather than a file\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "\n",
      "            PDF is generated via latex\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\n",
      "\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "\n",
      "            Multiple notebooks can be given at the command line in a couple of\n",
      "            different ways:\n",
      "\n",
      "            > jupyter nbconvert notebook*.ipynb\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "\n",
      "            or you can specify the notebooks list in a config file, containing::\n",
      "\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "\n",
      "            > jupyter nbconvert --config mycfg.py\n",
      "\n",
      "To see all available configurables, use `--help-all`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'project_2.ipynb' matched no files\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert project_2.ipynb --to html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3b49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
